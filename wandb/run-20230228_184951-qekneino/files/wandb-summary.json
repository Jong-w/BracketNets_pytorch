{"training/episode/reward": 0, "training/episode/length": 100, "_timestamp": 1677577813.461812, "_runtime": 22.19144892692566, "_step": 33, "loss/total_fun_loss": 0.9813025593757629, "loss/worker": 0.015930701047182083, "loss/manager": -0.0024716334883123636, "loss/value_worker": 0.4985905587673187, "loss/value_manager": 0.4961901605129242, "worker/entropy": 1.909014105796814, "worker/advantage": -0.009471693076193333, "worker/intrinsic_reward": 0.012242000550031662, "manager/cosines": 0.002189839258790016, "manager/advantage": 0.034517306834459305, "test/episode/reward": 0.991, "test/episode/length": 465, "test/mean/reward": 0.991, "test/mean/length": 474.375}