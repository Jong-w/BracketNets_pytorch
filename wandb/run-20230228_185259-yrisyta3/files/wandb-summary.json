{"training/episode/reward": 0, "training/episode/length": 100, "_timestamp": 1677578096.5040798, "_runtime": 116.93742990493774, "_step": 526, "loss/total_fun_loss": 0.9468644857406616, "loss/worker": 0.05542045086622238, "loss/manager": -0.0009296046337112784, "loss/value_worker": 0.5015745759010315, "loss/value_manager": 0.49979931116104126, "worker/entropy": 1.8565362691879272, "worker/advantage": -0.022083895280957222, "worker/intrinsic_reward": -0.018480973318219185, "manager/cosines": -0.008996076881885529, "manager/advantage": 0.028953146189451218, "test/episode/reward": 0.991, "test/episode/length": 465, "test/mean/reward": 0.991, "test/mean/length": 474.375}