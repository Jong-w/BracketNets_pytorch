{"training/episode/reward": 0, "training/episode/length": 200, "_timestamp": 1677578439.3965921, "_runtime": 296.81383323669434, "_step": 407, "loss/total_fun_loss": 0.941048264503479, "loss/worker": 0.06225327029824257, "loss/manager": -0.0035369768738746643, "loss/value_worker": 0.49862897396087646, "loss/value_manager": 0.5011543035507202, "worker/entropy": 1.873043179512024, "worker/advantage": -0.021552693098783493, "worker/intrinsic_reward": -0.026503846049308777, "manager/cosines": -0.012133711948990822, "manager/advantage": 0.023624103516340256, "test/episode/reward": 0.991, "test/episode/length": 465, "test/mean/reward": 0.991, "test/mean/length": 474.375}